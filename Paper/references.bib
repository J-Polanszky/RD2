
@phdthesis{grech_creating_2023,
  address  = {Paola, Malta},
  type     = {Bachelor's},
  title    = {Creating {Difficulty} {Levels} with {Reinforcement} {Learning} in a {Strategy} {Game}},
  language = {English},
  school   = {Malta College of Arts Science and Technology (MCAST)},
  author   = {Grech, Georg},
  month    = jun,
  year     = {2023},
  file     = {PDF:C\:\\Users\\User\\Zotero\\storage\\M6G6U5FL\\Grech - Creating Difficulty Levels with Reinforcement Learning in a Strategy Game.pdf:application/pdf}
}

@inproceedings{bin_ramlan_implementation_2021,
  address   = {Batu Pahat, Malaysia},
  title     = {The {Implementation} of {Reinforcement} {Learning} {Algorithm} for {AI} {Bot} in {Fighting} {Video} {Game}},
  copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
  isbn      = {978-1-6654-3632-8},
  url       = {https://ieeexplore.ieee.org/document/9567749/},
  doi       = {10.1109/ISAMSR53229.2021.9567749},
  urldate   = {2025-03-16},
  booktitle = {2021 4th {International} {Symposium} on {Agents}, {Multi}-{Agent} {Systems} and {Robotics} ({ISAMSR})},
  publisher = {IEEE},
  author    = {Bin Ramlan, Adi Aiman and Ali, Azliza Mohd and Abdul Hamid, Nurzeatul Hamimah and Osman, Rozianawaty},
  month     = sep,
  year      = {2021},
  pages     = {96--100}
}

@inproceedings{zhasulanov_enhancing_2024,
  title     = {Enhancing {Gameplay} {Experience} {Through} {Reinforcement} {Learning} in {Games}},
  doi       = {10.1109/SIST61555.2024.10629511},
  booktitle = {2024 {IEEE} 4th {International} {Conference} on {Smart} {Information} {Systems} and {Technologies} ({SIST})},
  author    = {Zhasulanov, Dinmukhammed and Marat, Bekarys and Erkin, Kuanysh and Omirgaliyev, Ruslan and Kushekkaliyev, Alman and Zhakiyev, Nurkhat},
  year      = {2024},
  keywords  = {Artificial intelligence, Artificial Intelligence (AI), Data processing, Economics, Game, Gameplay Experience, Games, Machine learning algorithms, ML Agents, Non-playable character (NPC), Reinforcement learning, Reinforcement Learning, Training, Unity},
  pages     = {175--180}
}

@inproceedings{raut_unity_2024,
  address    = {RAIPUR, India},
  title      = {Unity {ML}-{Agents}: {Revolutionizing} {Gaming} {Through} {Reinforcement} {Learning}},
  copyright  = {https://doi.org/10.15223/policy-029},
  isbn       = {979-8-3503-9532-7},
  shorttitle = {Unity {ML}-{Agents}},
  url        = {https://ieeexplore.ieee.org/document/10692314/},
  doi        = {10.1109/WCONF61366.2024.10692314},
  urldate    = {2025-03-16},
  booktitle  = {2024 2nd {World} {Conference} on {Communication} \&amp; {Computing} ({WCONF})},
  publisher  = {IEEE},
  author     = {Raut, Umesh and Galchhaniya, Prathmesh and Nehete, Anish and Shinde, Rohan and Bhoite, Avaneesh},
  month      = jul,
  year       = {2024},
  pages      = {1--7}
}

@article{vinyals_grandmaster_2019,
  title     = {Grandmaster level in {StarCraft} {II} using multi-agent reinforcement learning},
  volume    = {575},
  copyright = {2019 The Author(s), under exclusive licence to Springer Nature Limited},
  issn      = {1476-4687},
  url       = {https://www.nature.com/articles/s41586-019-1724-z},
  doi       = {10.1038/s41586-019-1724-z},
  abstract  = {Many real-world applications require artificial agents to compete and coordinate with other agents in complex environments. As a stepping stone to this goal, the domain of StarCraft has emerged as an important challenge for artificial intelligence research, owing to its iconic and enduring status among the most difficult professional esports and its relevance to the real world in terms of its raw complexity and multi-agent challenges. Over the course of a decade and numerous competitions1–3, the strongest agents have simplified important aspects of the game, utilized superhuman capabilities, or employed hand-crafted sub-systems4. Despite these advantages, no previous agent has come close to matching the overall skill of top StarCraft players. We chose to address the challenge of StarCraft using general-purpose learning methods that are in principle applicable to other complex domains: a multi-agent reinforcement learning algorithm that uses data from both human and agent games within a diverse league of continually adapting strategies and counter-strategies, each represented by deep neural networks5,6. We evaluated our agent, AlphaStar, in the full game of StarCraft II, through a series of online games against human players. AlphaStar was rated at Grandmaster level for all three StarCraft races and above 99.8\% of officially ranked human players.},
  language  = {en},
  number    = {7782},
  urldate   = {2025-03-16},
  journal   = {Nature},
  author    = {Vinyals, Oriol and Babuschkin, Igor and Czarnecki, Wojciech M. and Mathieu, Michaël and Dudzik, Andrew and Chung, Junyoung and Choi, David H. and Powell, Richard and Ewalds, Timo and Georgiev, Petko and Oh, Junhyuk and Horgan, Dan and Kroiss, Manuel and Danihelka, Ivo and Huang, Aja and Sifre, Laurent and Cai, Trevor and Agapiou, John P. and Jaderberg, Max and Vezhnevets, Alexander S. and Leblond, Rémi and Pohlen, Tobias and Dalibard, Valentin and Budden, David and Sulsky, Yury and Molloy, James and Paine, Tom L. and Gulcehre, Caglar and Wang, Ziyu and Pfaff, Tobias and Wu, Yuhuai and Ring, Roman and Yogatama, Dani and Wünsch, Dario and McKinney, Katrina and Smith, Oliver and Schaul, Tom and Lillicrap, Timothy and Kavukcuoglu, Koray and Hassabis, Demis and Apps, Chris and Silver, David},
  month     = nov,
  year      = {2019},
  note      = {Publisher: Nature Publishing Group},
  keywords  = {Computer science, Statistics},
  pages     = {350--354}
}

@incollection{csikszentmihalyi_flow_1990,
  title  = {Flow: {The} {Psychology} of {Optimal} {Experience}},
  author = {Csikszentmihalyi, Mihaly},
  month  = jan,
  year   = {1990}
}

@article{noauthor_comparative_nodate,
  title    = {Comparative {Analysis} of {Game} {Development} {Techniques}: {Using} {Finite} {State} {Machine}, {Physics} {Simulation}, {Path} {Finding}, {Event} {Handling}},
  abstract = {This paper delves into the core techniques pivotal to game development: Finite State Machines (FSMs), Physics Simulation, Event Handling, and Path Finding. These techniques serve as pillars in defining the intricate behaviors and dynamics within games, influencing gameplay mechanics, realism, and the overall player experience. By conducting a comprehensive comparative analysis, the aim is to unveil the nuanced attributes of each technique, elucidating their strengths, weaknesses, and diverse applications within the realm of game development. Through this examination, developers can gain valuable insights into the optimal utilization of these techniques, enabling them to craft immersive and captivating gaming experiences tailored to their specific design objectives and player expectations.},
  language = {en},
  file     = {PDF:C\:\\Users\\User\\Zotero\\storage\\8G3V4F7F\\Comparative Analysis of Game Development Techniques Using Finite State Machine, Physics Simulation,.pdf:application/pdf}
}

@article{jagdale_finite_2021,
  title    = {Finite {State} {Machine} in {Game} {Development}},
  doi      = {10.48175/IJARSCT-2062},
  abstract = {Finite State Machine is one of the oldest techniques in gaming where it was used in old games like PACMAN and new games like TOMB RAIDER also. In all these games one major goal was to make non player characters more intelligent. There are some advance types also available but FSM still is one of the most used technique for non-player characters. The main goal of this paper is to explain how FSM works, how to create FSM and implement it in games using scripting or visual scripting. Hierarchical Finite State Machine is also discussed in this paper as it overcomes the limitations of older simple FSM. Using FSM, we can create intelligent AI agents. We can implement FSM and HFSM in games to make NPS’s behave like AI.},
  author   = {Jagdale, Devang},
  month    = oct,
  year     = {2021},
  pages    = {384--390}
}

@misc{noauthor_finite_2020,
  title    = {Finite {State} {Machine} {Explained}},
  url      = {https://www.freecodecamp.org/news/finite-state-machines/},
  abstract = {The finite state machine (FSM) is a software design pattern where a given model transitions to other behavioral states through external input. Understanding the Finite State Machine A FSM is defined by its states, its initial state and the transition...},
  language = {en},
  urldate  = {2025-04-20},
  journal  = {freeCodeCamp.org},
  month    = jan,
  year     = {2020},
  file     = {Snapshot:C\:\\Users\\User\\Zotero\\storage\\MJMX52B2\\finite-state-machines.html:text/html}
}
